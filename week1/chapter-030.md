
## Number of parameters in models(log scale)

GPT-1은 파라미터(가중치)의 숫자가 117M였다. 이후 등장하는 모델들은 가중치가 지수적으로 증가한다. GPT-2는 1.5B, GPT-3은 175B, GPT-4은 1.76T 만큼 파라미터 개수가 증가했다. 오픈소스 모델들도 꽤 큰 파라미터 수를 갖는다. Gemma는 2B, Mixtral은 140B 갖는다. Llama 3.1은 8B, 70B, 405B 토큰을 갖는다.  